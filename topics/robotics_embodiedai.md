# Basic Knowledge


# Paper List
## 1. Diffusion Model for Planning, Policy, and RL
[Diffusion Model for Planning, Policy and RL](./diffusion_model.md/#1-diffusion-model-for-planning-policy-and-rl)

## 2. LLM for robotics
[LLM for Robotics](./llm.md/#4-llm-for-robotics)

## 3. Vision-related
* **[arXiv 2023]** D<sup>3</sup> Fields: Dynamic 3D Descriptor Fields for Zero-Shot Generalizable Robotic Manipulation, [website](https://robopil.github.io/d3fields/)

* **[CoRL 2020]** Transporter Networks: Rearranging the Visual World for Robotic Manipulation, [website](https://transporternets.github.io)


## 4. Affordance
* **[CoRL 2022]** Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation, [website](https://peract.github.io/)

* **[arXiv 2024]** Robo-ABC: Affordance Generalization Beyond Categories via Semantic Correspondence for Robot Manipulation, [arXiv](https://arxiv.org/abs/2401.07487)

* **[arXiv 2024]** PreAfford: Universal Affordance-Based Pre-Grasping for Diverse Objects and Environments, [arXiv](https://air-discover.github.io/PreAfford/)

* **[ICLR 2022]** VAT-Mart: Learning Visual Action Trajectory Proposals for Manipulating 3D ARTiculated Objects, [website](https://hyperplane-lab.github.io/vat-mart/)

* **[ICLR 2023]** DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Object Manipulation, [arXiv](https://arxiv.org/abs/2207.01971)

* **[CVPR 2022]** Joint Hand Motion and Interaction Hotspots Prediction from Egocentric Videos, [website](https://stevenlsw.github.io/hoi-forecast/)

* **[ICCV 2023]** AffordPose: A Large-scale Dataset of Hand-Object Interactions with Affordance-driven Hand Pose, [website](https://affordpose.github.io/)_

## 5. Pose Estimation and Tracking
* **[CVPR 2024 (Highlight)]** FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects, [website](https://nvlabs.github.io/FoundationPose/)

* **[CVPR 2023 (Highlight)]** GAPartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts, [website](https://pku-epic.github.io/GAPartNet/)

* **[arXiv 2023]** GAMMA: Generalizable Articulation Modeling and Manipulation for Articulated Objects, [website](https://sites.google.com/view/gamma-articulation)

* **[arXiv 2024]** ManiPose: A Comprehensive Benchmark for Pose-aware Object Manipulation in Robotics, [website](https://sites.google.com/view/manipose)

## 6. Dataset & Benchmark
* **[arXiv 2024]** Empowering Embodied Manipulation: A Bimanual-Mobile Robot Manipulation Dataset for Household Tasks, [website](https://embodiedrobot.github.io/), [zhihu](https://zhuanlan.zhihu.com/p/688624666?utm_medium=social&utm_psn=1756405102318243840&utm_source=wechat_session)


## TO READ

* Where2Act: From Pixels to Actions for Articulated 3D Objects

* PreAfford: Universal Affordance-Based Pre-Grasping for Diverse Objects and Environments

* Decision Transformer: Reinforcement Learning via Sequence Modeling

* Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis

* AO-Grasp: Articulated Object Grasp Generation

* Human-to-Robot Imitation in the Wild

* RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots

* SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation https://sam-embodied.github.io/, ICML2024

* https://progprompt.github.io/

* PerAct, Act3D

